{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374ca4fa-c405-4a10-a412-6e007ab129ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-17 11:37:03,153 | INFO     | Starting Aadhaar Health Analysis\n",
      "status\n",
      "Under-covered    3\n",
      "Healthy          3\n",
      "2026-01-17 11:37:03,274 | INFO     | CSV saved to ..\\outputs\\aadhaar_health_20260117_1137.csv\n",
      "    state_name      district        status  priority  load_score  shortfall_pct\n",
      "Andhra Pradesh       Krishna Under-covered         3       1.611          0.050\n",
      "Andhra Pradesh    Srikakulam Under-covered         3       1.618          0.398\n",
      "    Tamil Nadu    Dharmapuri Under-covered         3       0.228          0.234\n",
      "Andhra Pradesh Visakhapatnam       Healthy         1       1.149          0.000\n",
      "    Tamil Nadu       Chennai       Healthy         1       1.068          0.000\n",
      "    Tamil Nadu    Coimbatore       Healthy         1       0.478          0.000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import re\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Jupyter protection\n",
    "if len(sys.argv) > 1 and sys.argv[1] == \"-f\":\n",
    "    sys.argv = [sys.argv[0]]\n",
    "    \n",
    "@dataclass\n",
    "class Thresholds:\n",
    "    load_warning: float = 1.2\n",
    "    load_high: float = 1.8\n",
    "    shortfall_severe: float = 0.60\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_dir: Path = Path(\"../data\")\n",
    "    output_dir: Path = Path(\"../outputs\")\n",
    "    log_dir: Path = Path(\"../logs\")\n",
    "    thresholds: Thresholds = field(default_factory=Thresholds)\n",
    "\n",
    "    state_map: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"TN\": \"Tamil Nadu\",\n",
    "        \"AP\": \"Andhra Pradesh\",\n",
    "        \"KA\": \"Karnataka\",\n",
    "        \"MH\": \"Maharashtra\",\n",
    "        \"DL\": \"Delhi\",\n",
    "        \"UP\": \"Uttar Pradesh\"\n",
    "    })\n",
    "\n",
    "    age_cols: List[str] = field(default_factory=lambda: [\n",
    "        \"age_0_5\", \"age_5_17\", \"age_18_greater\"\n",
    "    ])\n",
    "\n",
    "    filename_regex: str = r\"^([A-Z]{2}),\\s*(.+?)(?:\\s*aadhaar.*)?$\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        for d in [self.data_dir, self.output_dir, self.log_dir]:\n",
    "            d.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "def setup_logging(config: Config) -> logging.Logger:\n",
    "    log_file = config.log_dir / f\"aadhaar_health_{datetime.now():%Y%m%d}.log\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s | %(levelname)-8s | %(message)s\",\n",
    "        handlers=[\n",
    "            logging.StreamHandler(sys.stdout),\n",
    "            logging.FileHandler(log_file, encoding=\"utf-8\")\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(\"AadhaarHealth\")\n",
    "\n",
    "class AadhaarProcessor:\n",
    "    def __init__(self, config: Config, logger: logging.Logger):\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "\n",
    "    def parse_filename(self, filename: str) -> Tuple[str, str]:\n",
    "        stem = Path(filename).stem\n",
    "        match = re.match(self.config.filename_regex, stem, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).upper(), match.group(2).title()\n",
    "        return \"UNK\", \"Unknown\"\n",
    "\n",
    "    def read_csv(self, path: Path) -> pd.DataFrame:\n",
    "        try:\n",
    "            return pd.read_csv(path, low_memory=False)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Read failed: {path.name} : {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def process_enrolments(self) -> pd.DataFrame:\n",
    "        files = list(self.config.data_dir.glob(\"*aadhaar_enrolments.csv\"))\n",
    "        rows = []\n",
    "\n",
    "        for f in files:\n",
    "            df = self.read_csv(f)\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            state, district = self.parse_filename(f.name)\n",
    "            if all(c in df.columns for c in self.config.age_cols):\n",
    "                total = df[self.config.age_cols].sum(axis=1)\n",
    "            else:\n",
    "                total = df.select_dtypes(include=np.number).sum(axis=1)\n",
    "\n",
    "            rows.append({\n",
    "                \"state\": state,\n",
    "                \"district\": district,\n",
    "                \"total_enrolments\": total.sum()\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    def process_updates(self, pattern: str, col_name: str) -> pd.DataFrame:\n",
    "        files = list(self.config.data_dir.glob(pattern))\n",
    "        totals = defaultdict(float)\n",
    "\n",
    "        for f in files:\n",
    "            df = self.read_csv(f)\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            state, district = self.parse_filename(f.name)\n",
    "            numeric = df.select_dtypes(include=np.number)\n",
    "            totals[(state, district)] += numeric.sum().sum()\n",
    "\n",
    "        return pd.DataFrame([\n",
    "            {\"state\": s, \"district\": d, col_name: v}\n",
    "            for (s, d), v in totals.items()\n",
    "        ])\n",
    "\n",
    "    def calculate_metrics(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        avg_updates = df[\"total_updates\"].mean()\n",
    "        avg_enrol = df[\"total_enrolments\"].mean()\n",
    "\n",
    "        df[\"updates_norm\"] = df[\"total_updates\"] / avg_updates\n",
    "        df[\"enrol_norm\"] = df[\"total_enrolments\"] / avg_enrol\n",
    "\n",
    "        df[\"load_score\"] = (\n",
    "            df[\"updates_norm\"] / df[\"enrol_norm\"]\n",
    "        ).replace([np.inf, -np.inf], 0).round(3)\n",
    "\n",
    "        df[\"shortfall_pct\"] = (\n",
    "            (avg_enrol - df[\"total_enrolments\"]) / avg_enrol\n",
    "        ).clip(lower=0).round(3)\n",
    "\n",
    "        df[\"shortfall_pctile\"] = (df[\"shortfall_pct\"].rank(pct=True) * 100).round(1)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def classify(self, row):\n",
    "        t = self.config.thresholds\n",
    "        if row[\"load_score\"] > t.load_high and row[\"shortfall_pctile\"] / 100 > t.shortfall_severe:\n",
    "            return 5, \"Critical\", \"Emergency response\"\n",
    "        if row[\"load_score\"] > t.load_high:\n",
    "            return 4, \"Overloaded\", \"Increase capacity\"\n",
    "        if row[\"shortfall_pctile\"] / 100 > t.shortfall_severe:\n",
    "            return 3, \"Under-covered\", \"Outreach required\"\n",
    "        if row[\"load_score\"] > t.load_warning:\n",
    "            return 2, \"Moderate\", \"Monitor\"\n",
    "        return 1, \"Healthy\", \"Maintain\"\n",
    "\n",
    "    def build_master(self) -> pd.DataFrame:\n",
    "        enrol = self.process_enrolments()\n",
    "        demo = self.process_updates(\"*aadhaar_demographic_updates.csv\", \"demo_updates\")\n",
    "        bio = self.process_updates(\"*aadhaar_biometric_updates.csv\", \"bio_updates\")\n",
    "\n",
    "        updates = demo.merge(bio, on=[\"state\", \"district\"], how=\"outer\").fillna(0)\n",
    "        updates[\"total_updates\"] = updates[\"demo_updates\"] + updates[\"bio_updates\"]\n",
    "\n",
    "        master = enrol.merge(updates, on=[\"state\", \"district\"], how=\"left\").fillna(0)\n",
    "        master = self.calculate_metrics(master)\n",
    "\n",
    "        master[[\"priority\", \"status\", \"action\"]] = pd.DataFrame(\n",
    "            master.apply(self.classify, axis=1).tolist(),\n",
    "            index=master.index\n",
    "        )\n",
    "\n",
    "        master[\"state_name\"] = master[\"state\"].map(self.config.state_map).fillna(master[\"state\"])\n",
    "        return master.sort_values(\"priority\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--format\", default=\"csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    config = Config()\n",
    "    logger = setup_logging(config)\n",
    "\n",
    "    logger.info(\"Starting Aadhaar Health Analysis\")\n",
    "\n",
    "    processor = AadhaarProcessor(config, logger)\n",
    "    master = processor.build_master()\n",
    "\n",
    "    print(master[\"status\"].value_counts().to_string())\n",
    "\n",
    "    out = config.output_dir / f\"aadhaar_health_{datetime.now():%Y%m%d_%H%M}.csv\"\n",
    "    master.to_csv(out, index=False)\n",
    "    logger.info(f\"CSV saved to {out}\")\n",
    "\n",
    "    print(master.head(10)[\n",
    "        [\"state_name\", \"district\", \"status\", \"priority\", \"load_score\", \"shortfall_pct\"]\n",
    "    ].to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed248a7-34fc-4cae-b5a3-f12684768cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

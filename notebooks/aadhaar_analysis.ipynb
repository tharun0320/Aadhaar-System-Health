{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba8313e-dfde-4dd9-a732-03115f5f353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-17 00:11:55,467 | INFO    | Starting Aadhaar Health Analysis\n",
      "2026-01-17 00:11:55,468 | INFO    | Found 6 enrolment files\n",
      "\n",
      "AADHAAR SYSTEM HEALTH SUMMARY\n",
      "status\n",
      "Under-covered    3\n",
      "Healthy          3\n",
      "2026-01-17 00:11:55,581 | INFO    | CSV saved to ..\\outputs\\aadhaar_health_20260117_0011.csv\n",
      "\n",
      "Top Priority Districts:\n",
      "    state_name      district        status  priority  load_score  shortfall_pct\n",
      "Andhra Pradesh       Krishna Under-covered         3       1.611          0.050\n",
      "Andhra Pradesh    Srikakulam Under-covered         3       1.618          0.398\n",
      "    Tamil Nadu    Dharmapuri Under-covered         3       0.228          0.234\n",
      "Andhra Pradesh Visakhapatnam       Healthy         1       1.149          0.000\n",
      "    Tamil Nadu       Chennai       Healthy         1       1.068          0.000\n",
      "    Tamil Nadu    Coimbatore       Healthy         1       0.478          0.000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "\n",
    "\n",
    "if len(sys.argv) > 1 and sys.argv[1] == \"-f\":\n",
    "    sys.argv = [sys.argv[0]]\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class AlertLevel(Enum):\n",
    "    INFO = \"INFO\"\n",
    "    WARNING = \"WARNING\"\n",
    "    CRITICAL = \"CRITICAL\"\n",
    "    EMERGENCY = \"EMERGENCY\"\n",
    "\n",
    "@dataclass\n",
    "class Thresholds:\n",
    "    load_warning: float = 1.2\n",
    "    load_high: float = 1.8\n",
    "    shortfall_warning: float = 0.35\n",
    "    shortfall_severe: float = 0.60\n",
    "    critical_district_limit: int = 5\n",
    "    max_load_anomaly: float = 3.0\n",
    "    min_enrolments_for_analysis: int = 100\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_dir: Path = Path(\"../data\")\n",
    "    output_dir: Path = Path(\"../outputs\")\n",
    "    log_dir: Path = Path(\"../logs\")\n",
    "\n",
    "    thresholds: Thresholds = field(default_factory=Thresholds)\n",
    "\n",
    "    state_map: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"TN\": \"Tamil Nadu\", \"AP\": \"Andhra Pradesh\", \"KA\": \"Karnataka\",\n",
    "        \"MH\": \"Maharashtra\", \"DL\": \"Delhi\", \"UP\": \"Uttar Pradesh\",\n",
    "        \"WB\": \"West Bengal\", \"GJ\": \"Gujarat\", \"RJ\": \"Rajasthan\",\n",
    "        \"PB\": \"Punjab\", \"KL\": \"Kerala\", \"MP\": \"Madhya Pradesh\",\n",
    "        \"BR\": \"Bihar\", \"OR\": \"Odisha\", \"HR\": \"Haryana\"\n",
    "    })\n",
    "\n",
    "    age_cols: List[str] = field(default_factory=lambda: [\n",
    "        \"age_0_5\", \"age_5_17\", \"age_18_greater\"\n",
    "    ])\n",
    "\n",
    "    filename_regex: str = r\"^([A-Z]{2}),\\s*(.+?)(?:\\s*aadhaar.*)?$\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        for d in [self.data_dir, self.output_dir, self.log_dir]:\n",
    "            d.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def setup_logging(config: Config) -> logging.Logger:\n",
    "    log_file = config.log_dir / f\"aadhaar_health_{datetime.now():%Y%m%d}.log\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s | %(levelname)-8s | %(message)s\",\n",
    "        handlers=[\n",
    "            logging.StreamHandler(sys.stdout),\n",
    "            logging.FileHandler(log_file, encoding=\"utf-8\")\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(\"AadhaarHealth\")\n",
    "\n",
    "\n",
    "class AadhaarProcessor:\n",
    "    def __init__(self, config: Config, logger: logging.Logger):\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "\n",
    "    def parse_filename(self, filename: str) -> Tuple[str, str]:\n",
    "        stem = Path(filename).stem\n",
    "        match = re.match(self.config.filename_regex, stem, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).upper(), match.group(2).title()\n",
    "        return \"UNK\", \"Unknown\"\n",
    "\n",
    "    def read_csv(self, path: Path) -> pd.DataFrame:\n",
    "        try:\n",
    "            return pd.read_csv(path, low_memory=False)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed reading {path.name}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def process_enrolments(self) -> pd.DataFrame:\n",
    "        files = list(self.config.data_dir.glob(\"*aadhaar_enrolments.csv\"))\n",
    "        self.logger.info(f\"Found {len(files)} enrolment files\")\n",
    "\n",
    "        rows = []\n",
    "        for f in files:\n",
    "            df = self.read_csv(f)\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            state, district = self.parse_filename(f.name)\n",
    "            if all(c in df.columns for c in self.config.age_cols):\n",
    "                total = df[self.config.age_cols].sum(axis=1)\n",
    "            else:\n",
    "                total = df.select_dtypes(include=np.number).sum(axis=1)\n",
    "\n",
    "            rows.append(pd.DataFrame({\n",
    "                \"state\": state,\n",
    "                \"district\": district,\n",
    "                \"total_enrolments\": total.sum()\n",
    "            }, index=[0]))\n",
    "\n",
    "        return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "    def process_updates(self, pattern: str, col_name: str) -> pd.DataFrame:\n",
    "        files = list(self.config.data_dir.glob(pattern))\n",
    "        totals = defaultdict(float)\n",
    "\n",
    "        for f in files:\n",
    "            df = self.read_csv(f)\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            state, district = self.parse_filename(f.name)\n",
    "            numeric = df.select_dtypes(include=np.number)\n",
    "            totals[(state, district)] += numeric.sum().sum()\n",
    "\n",
    "        return pd.DataFrame([\n",
    "            {\"state\": s, \"district\": d, col_name: v}\n",
    "            for (s, d), v in totals.items()\n",
    "        ])\n",
    "\n",
    "   \n",
    "    def calculate_metrics(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        result = df.copy()\n",
    "\n",
    "        avg_updates = result[\"total_updates\"].mean()\n",
    "        avg_enrol   = result[\"total_enrolments\"].mean()\n",
    "\n",
    "        result[\"updates_norm\"] = result[\"total_updates\"] / avg_updates\n",
    "        result[\"enrol_norm\"]   = result[\"total_enrolments\"] / avg_enrol\n",
    "\n",
    "        result[\"load_score\"] = (\n",
    "            result[\"updates_norm\"] / result[\"enrol_norm\"]\n",
    "        ).replace([np.inf, -np.inf], 0).round(3)\n",
    "\n",
    "        result[\"shortfall_pct\"] = (\n",
    "            (avg_enrol - result[\"total_enrolments\"]) / avg_enrol\n",
    "        ).clip(lower=0).round(3)\n",
    "\n",
    "        result[\"load_pctile\"] = (result[\"load_score\"].rank(pct=True) * 100).round(1)\n",
    "        result[\"shortfall_pctile\"] = (result[\"shortfall_pct\"].rank(pct=True) * 100).round(1)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def classify(self, row):\n",
    "        t = self.config.thresholds\n",
    "        if row[\"load_score\"] > t.load_high and row[\"shortfall_pctile\"] / 100 > t.shortfall_severe:\n",
    "            return 5, \"Critical\", \"Emergency response: mobile vans + staff surge\"\n",
    "        if row[\"load_score\"] > t.load_high:\n",
    "            return 4, \"Overloaded\", \"Increase capacity and staffing\"\n",
    "        if row[\"shortfall_pctile\"] / 100 > t.shortfall_severe:\n",
    "            return 3, \"Under-covered\", \"Outreach and awareness campaigns\"\n",
    "        if row[\"load_score\"] > t.load_warning:\n",
    "            return 2, \"Moderate\", \"Monitor closely\"\n",
    "        return 1, \"Healthy\", \"Maintain operations\"\n",
    "\n",
    "    def build_master(self) -> pd.DataFrame:\n",
    "        enrol = self.process_enrolments()\n",
    "        demo = self.process_updates(\"*aadhaar_demographic_updates.csv\", \"demo_updates\")\n",
    "        bio  = self.process_updates(\"*aadhaar_biometric_updates.csv\", \"bio_updates\")\n",
    "\n",
    "        updates = demo.merge(bio, on=[\"state\", \"district\"], how=\"outer\").fillna(0)\n",
    "        updates[\"total_updates\"] = updates[\"demo_updates\"] + updates[\"bio_updates\"]\n",
    "\n",
    "        master = enrol.merge(updates, on=[\"state\", \"district\"], how=\"left\").fillna(0)\n",
    "        master = self.calculate_metrics(master)\n",
    "\n",
    "        master[[\"priority\", \"status\", \"action\"]] = pd.DataFrame(\n",
    "            master.apply(self.classify, axis=1).tolist(),\n",
    "            index=master.index\n",
    "        )\n",
    "\n",
    "        master[\"state_name\"] = master[\"state\"].map(self.config.state_map).fillna(master[\"state\"])\n",
    "\n",
    "        return master.sort_values(\"priority\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Aadhaar System Health Monitor\")\n",
    "    parser.add_argument(\"--format\", choices=[\"csv\"], default=\"csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    config = Config()\n",
    "    logger = setup_logging(config)\n",
    "\n",
    "    logger.info(\"Starting Aadhaar Health Analysis\")\n",
    "\n",
    "    processor = AadhaarProcessor(config, logger)\n",
    "    master = processor.build_master()\n",
    "\n",
    "    print(\"\\nAADHAAR SYSTEM HEALTH SUMMARY\")\n",
    "    print(master[\"status\"].value_counts().to_string())\n",
    "\n",
    "    out = config.output_dir / f\"aadhaar_health_{datetime.now():%Y%m%d_%H%M}.csv\"\n",
    "    master.to_csv(out, index=False)\n",
    "    logger.info(f\"CSV saved to {out}\")\n",
    "\n",
    "    print(\"\\nTop Priority Districts:\")\n",
    "    print(master.head(10)[\n",
    "        [\"state_name\", \"district\", \"status\", \"priority\", \"load_score\", \"shortfall_pct\"]\n",
    "    ].to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3228907-c43a-40f1-af51-4424d4e29b33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
